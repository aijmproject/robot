{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import librosa # library traitement du son (audio to image )  \n",
    "import librosa.display\n",
    "import IPython.display\n",
    "from glob import glob\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten \n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BabyCryPredictor():\n",
    "    \"\"\"\n",
    "    Class to classify a new audio signal and determine if it's a baby cry\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.filepath = 'trained_model/cnn_baby.hdf5'\n",
    "        self.filename = 'record.wav'\n",
    "        self.path_filename= 'temp'\n",
    "        self.path_to_save='temp/'\n",
    "        self.image_path = \"temp/record.wav.png\"\n",
    "        self.audio_path = \"temp/record.wav\"\n",
    "\n",
    "    def reader(self):\n",
    "        fs = 22050\n",
    "        duration = 7\n",
    "        print('speak')\n",
    "        x = sd.rec(int(duration * fs), fs , 1, blocking=True)\n",
    "        print('stop')\n",
    "        \n",
    "        x = np.squeeze(x)\n",
    "        write('temp/record.wav', fs, x)\n",
    "        \n",
    "    def create_spectrogram(self):\n",
    "       \n",
    "                       \n",
    "        plt.interactive(False)\n",
    "        clip, sample_rate = librosa.load(self.path_filename + '/' + self.filename, sr=None, duration = 5.0)\n",
    "        fig = plt.figure(figsize=[0.72,0.72])\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "        librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "        image_record  = os.path.basename(self.filename) + '.png'\n",
    "        plt.savefig(self.path_to_save + image_record, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "        plt.close()    \n",
    "        fig.clf()\n",
    "        plt.close(fig)\n",
    "        plt.close('all')   \n",
    "        \n",
    "    def model(self):\n",
    "        classifier = Sequential()\n",
    "        #adding a convolution layer\n",
    "        classifier.add(Convolution2D(32 , 3 , 3 , input_shape = (64 , 64 , 3) , activation = 'relu'))\n",
    "        classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "        #adding the second convolution layer\n",
    "        classifier.add(Convolution2D(32 , 3, 3, activation = 'relu'))\n",
    "        classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "        classifier.add(Flatten())\n",
    "\n",
    "        classifier.add(Dense(output_dim =  128 , activation = 'relu'))\n",
    "        classifier.add(Dense(output_dim = 128 , activation = 'relu'))\n",
    "        classifier.add(Dense(output_dim = 1 , activation = 'sigmoid'))\n",
    "        return classifier\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self):\n",
    "        self.reader()\n",
    "        self.create_spectrogram()\n",
    "        \n",
    "        test_image = image.load_img(self.image_path, target_size = (64, 64))\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        cnn_model = self.model()\n",
    "        cnn_model.load_weights(self.filepath)\n",
    "        result = cnn_model.predict(test_image)\n",
    "        #training_set.class_indices\n",
    "        if result[0][0] == 1:\n",
    "            prediction = False\n",
    "\n",
    "        else:\n",
    "            prediction = True\n",
    "        os.remove(self.image_path)\n",
    "        os.remove(self.audio_path)\n",
    "        return prediction\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =BabyCryPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak\n",
      "stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "C:\\Users\\kibas\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brouillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrement d'un son\n",
    "fs = 22050\n",
    "duration = 7 * 400\n",
    "print('speak')\n",
    "x = sd.rec(int(duration * fs), fs , 1, blocking=True)\n",
    "print('stop')\n",
    "\n",
    "x = np.squeeze(x)\n",
    "write('data_silence/record.wav', fs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 4.53514747e-05, 9.07029493e-05, ...,\n",
       "       2.79999991e+03, 2.79999995e+03, 2.80000000e+03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,fs = librosa.load('data_silence/record.wav')\n",
    "Time = np.linspace(0, len(x) / fs, num=len(x))\n",
    "Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decouper un son \n",
    "\n",
    "from pydub import AudioSegment\n",
    "t1 = 0 #Works in milliseconds\n",
    "t2 = 7000\n",
    "i = 1\n",
    "while t2 < (2800000):\n",
    "\n",
    "    newAudio = AudioSegment.from_wav(\"data_silence/record.wav\")\n",
    "    newAudio = newAudio[t1:t2]\n",
    "    t1 = t2\n",
    "    t2 = t2 +7000\n",
    "    newAudio.export('slience_bruit' + str(i) + '.wav', format=\"wav\") \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# creation de class qui cree des spectrogramm Ã  partir d'un path audio\n",
    "class audio_to_spectro():\n",
    "    \"\"\"\n",
    "    Class to classify a new audio signal and determine if it's a baby cry\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.path = \"data_silence_bruit\"\n",
    "        self.label = 0\n",
    "        \n",
    "    def create_spectrogram(self):\n",
    "       \n",
    "                  \n",
    "        plt.interactive(False)\n",
    "        clip, sample_rate = librosa.load(self.df['path'] + '/' + df['audio_name'] sr=None, duration = 5.0)\n",
    "        fig = plt.figure(figsize=[0.72,0.72])\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "        librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "        image_record  = os.path.basename(self.df['audo_name']) + '.png'\n",
    "        plt.savefig(self.path_to_save + image_record, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "        plt.close()    \n",
    "        fig.clf()\n",
    "        plt.close(fig)\n",
    "        plt.close('all')   \n",
    "        \n",
    "    def load_df(self):\n",
    "    \n",
    "  \n",
    "        audio_files = glob(self.path + '/*')\n",
    "        audio_files = [os.path.basename(i) for i in audio_files] # just pour enlever le path et garder que name de l audio\n",
    "        y = [self.label for i in range(0, len(audio_files))]\n",
    "        df = pd.DataFrame({'path':self.path,\n",
    "                           'audio_name':audio_files,\n",
    "                          'label':self.label})\n",
    "        \n",
    "        X = df['audio_name'].values\n",
    "        y = df['label'].values\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        self.dictionnaire_path =   dict(zip(df['audio_name'], df['path']) )\n",
    "        self.df = df\n",
    "        \n",
    "    def load(self):\n",
    "\n",
    "        for i,j in zip(self.X_train,self.y_train):\n",
    "            if j == 1:\n",
    "                self.path_to_save = self.path + \"/\" + \"training_set/crying\" + \"/\"\n",
    "                self.create_spectrogram(i, self.path_to_save)\n",
    "            else:\n",
    "                self.create_spectrogram(i, 'data_silence_bruit/training_set/not_crying/')\n",
    "\n",
    "        for i,j in zip(X_test,y_test):\n",
    "            if j == 1:\n",
    "                self.create_spectrogram(i,self.dictionnaire_path[i], 'data_silence_bruit/test_set/crying/')\n",
    "            else:\n",
    "                self.create_spectrogram(i,self.dictionnaire_path[i], 'data_silence_bruit/test_set/not_crying/')\n",
    "        chargement = 'transformation mfccs effectuÃ©e'\n",
    "        return  chargement\n",
    "\n",
    "   \n",
    "        \n",
    "    \n",
    "        \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_spectrogram() takes 1 positional argument but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-4d098b2b0393>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudio_to_spectro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-bfa58b49efd7>\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_spectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionnaire_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data_silence_bruit/training_set/crying/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_spectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdictionnaire_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data_silence_bruit/training_set/not_crying/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: create_spectrogram() takes 1 positional argument but 4 were given"
     ]
    }
   ],
   "source": [
    "b = audio_to_spectro()\n",
    "b.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
